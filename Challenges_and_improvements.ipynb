{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtB+ltd0khbtDV3gPtwnsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gladw311/AI-4-SE-Group-60-Week-5/blob/main/Challenges_and_improvements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lavVW-Ic4O1D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most Challenging Part:\n",
        "The most challenging part of the AI workflow was the testing and validation phase. This stage requires setting up rigorous metrics, edge cases, and bias detection to ensure the model performs accurately across various scenarios. It’s not just about checking if it works—but making sure it works fairly and reliably, which can be difficult with complex or unstructured data.\n",
        "\n",
        "\n",
        "\n",
        "Improvements with More Time/Resources:\n",
        "With more time or resources, I would focus on automating portions of the data preprocessing and hyperparameter tuning steps using AutoML tools. Access to more computational power or cloud-based model training (like Azure ML or AWS SageMaker) would speed up experimentation and allow for testing larger models with more advanced architectures.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ywv9yt-Q4VAr"
      }
    }
  ]
}